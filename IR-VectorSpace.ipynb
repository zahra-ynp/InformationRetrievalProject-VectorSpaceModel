{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56547735",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87d0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(filepath):\n",
    "\n",
    "    \"\"\"\n",
    "    Parses the Cranfield dataset from the given file.\n",
    "\n",
    "    This function reads the file, identifies the documents based on the '.I' marker,\n",
    "    and extracts text from the '.T' (Title) and '.W' (Words) fields.\n",
    "    \n",
    "    Returns:\n",
    "         A list of strings, where each string is the raw, unprocessed text of a document.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty list to hold the raw text of all documents.\n",
    "    documents_raw = []\n",
    "\n",
    "    # A variable to hold the text of the current document being processed.\n",
    "    current_text = \"\"\n",
    "    \n",
    "    # A boolean flag to track if the current line is part of a text field (.T or .W).\n",
    "    is_text_section = False\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        # Iterate through each line in the file.\n",
    "        for line in f:\n",
    "            # A line starting with '.I' marks the beginning of a new document.\n",
    "            if line.startswith('.I'):\n",
    "                # If 'current_text' is not empty, it means we have finished reading a document.\n",
    "                if current_text:\n",
    "                    # Append the complete text of the previous document to our list.\n",
    "                    documents_raw.append(current_text.strip())\n",
    "                \n",
    "                # Reset 'current_text' to start for the new document.\n",
    "                current_text = \"\"\n",
    "                # Reset the flag, as we don't know what the next section will be.\n",
    "                is_text_section = False\n",
    "\n",
    "            # If a line starts with '.T' or '.W', it's a section we want to capture.\n",
    "            elif line.startswith(('.T', '.W')):\n",
    "                # Set our flag to True to start accumulating text from this and subsequent lines.\n",
    "                is_text_section = True\n",
    "            \n",
    "            # If a line starts with '.A' or '.B', it's metadata we want to ignore.\n",
    "            elif line.startswith(('.A', '.B')):\n",
    "                # Set our flag to False to stop accumulating text until we see a new .T or .W.\n",
    "                is_text_section = False\n",
    "                \n",
    "            # If the line doesn't start with a marker AND our flag is True...\n",
    "            elif is_text_section:\n",
    "                # ...it's a continuation of a title or abstract, so append it.\n",
    "                # We add a space to ensure words from different lines are not merged together.\n",
    "                current_text += line.strip() + \" \"\n",
    "\n",
    "    # After the loop finishes, the last document's text is still held in 'current_text'.\n",
    "    # This final check ensures the very last document in the file is added to the list.\n",
    "    if current_text:\n",
    "        documents_raw.append(current_text.strip())\n",
    "\n",
    "    # A confirmation message for loading\n",
    "    print(f\"Successfully loaded {len(documents_raw)} raw documents.\")\n",
    "    \n",
    "    # Return the final list\n",
    "    return documents_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae641e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1398 raw documents.\n"
     ]
    }
   ],
   "source": [
    "articles = import_dataset('./Dataset/cran.all.1400')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b4d525",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ffab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# You only need to run these lines once to download the necessary NLTK packages.\n",
    "# try:\n",
    "#     stopwords.words('english')\n",
    "# except LookupError:\n",
    "#     nltk.download('stopwords')\n",
    "# try:\n",
    "#     nltk.data.find('tokenizers/punkt')\n",
    "# except LookupError:\n",
    "#     nltk.download('punkt')\n",
    "# try:\n",
    "#     nltk.data.find('corpora/wordnet')\n",
    "# except LookupError:\n",
    "#     nltk.download('wordnet')\n",
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd86763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(raw_docs, method='lemmatize'):\n",
    "    \"\"\"\n",
    "    Takes a list of raw document strings and applies all preprocessing steps.\n",
    "\n",
    "    Args:\n",
    "        raw_docs (list of str): The list of unprocessed document texts.\n",
    "        method (str): The word reduction method to use. Can be 'lemmatize' (default)\n",
    "                      or 'stem'.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists, where each inner list contains the processed tokens\n",
    "        of a single document.\n",
    "    \"\"\"\n",
    "    # Initialize lists and objects for preprocessing.\n",
    "    processed_docs = []\n",
    "    \n",
    "    # 1. TOKENIZATION AND NORMALIZATION (LOWERCASE, PUNCTUATION REMOVAL)\n",
    "    # The tokenizer will split the document text into a list of words.\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    # 2. STOP WORD REMOVAL\n",
    "    # Load the set of English stop words. Using a set provides fast lookups.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # 3. STEMMING / LEMMATIZATION\n",
    "    # Initialize the chosen processor.\n",
    "    if method == 'lemmatize':\n",
    "        processor = WordNetLemmatizer()\n",
    "        process_func = processor.lemmatize\n",
    "    elif method == 'stem':\n",
    "        processor = PorterStemmer()\n",
    "        process_func = processor.stem\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'lemmatize' or 'stem'\")\n",
    "\n",
    "    # Process each document in the input list.\n",
    "    for doc in raw_docs:\n",
    "        # Lowercase the document text.\n",
    "        doc = doc.lower()\n",
    "        \n",
    "        # Use the tokenizer to get a list of alphabetic tokens.\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        \n",
    "        # Filter out stop words from the token list.\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # Apply the chosen processing (lemmatization or stemming) to each token.\n",
    "        processed_tokens = [process_func(token) for token in filtered_tokens]\n",
    "        \n",
    "        # Add the final list of processed tokens to our main list.\n",
    "        processed_docs.append(processed_tokens)\n",
    "        \n",
    "    print(f\"Finished preprocessing all documents using the '{method}' method.\")\n",
    "    return processed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af9f56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing all documents using the 'lemmatize' method.\n",
      "\n",
      "--- Verification Sample (Document #2) ---\n",
      "\n",
      "[Raw Text]:\n",
      "simple shear flow past a flat plate in an incompressible fluid of small viscosity . simple shear flow past a flat plate in an incompressible fluid of small viscosity . in the study of high-speed viscous flow past a two-dimensional body it is usually necessary to consider a curved shock wave emitting from the nose or leading edge of the body .  consequently, there exists an inviscid rotational flow region between the shock wave and the boundary layer .  such a situation arises, for instance, in the study of the hypersonic viscous flow past a flat plate .  the situation is somewhat different from prandtl's classical boundary-layer problem . in prandtl's original problem the inviscid free stream outside the boundary layer is irrotational while in a hypersonic boundary-layer problem the inviscid free stream must be considered as rotational .  the possible effects of vorticity have been recently discussed by ferri and libby .  in the present paper, the simple shear flow past a flat plate in a fluid of small viscosity is investigated .  it can be shown that this problem can again be treated by the boundary-layer approximation, the only novel feature being that the free stream has a constant vorticity .  the discussion here is restricted to two-dimensional incompressible steady flow .\n",
      "\n",
      "[Processed Tokens]:\n",
      "['simple', 'shear', 'flow', 'past', 'flat', 'plate', 'incompressible', 'fluid', 'small', 'viscosity', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'incompressible', 'fluid', 'small', 'viscosity', 'study', 'high', 'speed', 'viscous', 'flow', 'past', 'two', 'dimensional', 'body', 'usually', 'necessary', 'consider', 'curved', 'shock', 'wave', 'emitting', 'nose', 'leading', 'edge', 'body', 'consequently', 'exists', 'inviscid', 'rotational', 'flow', 'region', 'shock', 'wave', 'boundary', 'layer', 'situation', 'arises', 'instance', 'study', 'hypersonic', 'viscous', 'flow', 'past', 'flat', 'plate', 'situation', 'somewhat', 'different', 'prandtl', 'classical', 'boundary', 'layer', 'problem', 'prandtl', 'original', 'problem', 'inviscid', 'free', 'stream', 'outside', 'boundary', 'layer', 'irrotational', 'hypersonic', 'boundary', 'layer', 'problem', 'inviscid', 'free', 'stream', 'must', 'considered', 'rotational', 'possible', 'effect', 'vorticity', 'recently', 'discussed', 'ferri', 'libby', 'present', 'paper', 'simple', 'shear', 'flow', 'past', 'flat', 'plate', 'fluid', 'small', 'viscosity', 'investigated', 'shown', 'problem', 'treated', 'boundary', 'layer', 'approximation', 'novel', 'feature', 'free', 'stream', 'constant', 'vorticity', 'discussion', 'restricted', 'two', 'dimensional', 'incompressible', 'steady', 'flow']\n"
     ]
    }
   ],
   "source": [
    "processed_articles = preprocess_text(articles)\n",
    "        \n",
    "# --- Display a sample to verify the process ---\n",
    "print(\"\\n--- Verification Sample (Document #2) ---\")\n",
    "        \n",
    "# Print the raw text of the second document (index 1)\n",
    "print(\"\\n[Raw Text]:\")\n",
    "print(articles[1])\n",
    "        \n",
    "# Print the same document after preprocessing\n",
    "print(\"\\n[Processed Tokens]:\")\n",
    "print(processed_articles[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa6c9d",
   "metadata": {},
   "source": [
    "Positional Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821d0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def make_positional_index(processed_docs):\n",
    "    \"\"\"\n",
    "    Builds a positional inverted index from the processed documents.\n",
    "\n",
    "    The index is a dictionary where keys are terms. The value for each term\n",
    "    is another dictionary, where keys are document IDs and values are lists\n",
    "    of the positions where the term appears in that document.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Indexing ---\")\n",
    "    \n",
    "    # We use a defaultdict of dicts to easily create nested structures.\n",
    "    # If a term is new, it will automatically be assigned an empty dictionary.\n",
    "    p_index = defaultdict(dict)\n",
    "\n",
    "    # Enumerate over the processed documents to get both the document ID (docid)\n",
    "    # and the list of tokens for that document. The index acts as the docID.\n",
    "    for docid, tokens in enumerate(processed_docs):\n",
    "        # Enumerate over the tokens in the current document to get both the\n",
    "        # position (pos) and the term itself.\n",
    "        for pos, term in enumerate(tokens):\n",
    "            # Check if the docid is already a key for this term.\n",
    "            if docid in p_index[term]:\n",
    "                # Append the new position to the existing list.\n",
    "                p_index[term][docid].append(pos)\n",
    "            else:\n",
    "                # If the docid is not a key, this is the first time the term\n",
    "                # Create a new list containing the current position.\n",
    "                p_index[term][docid] = [pos]\n",
    "\n",
    "    print(f\"Finished indexing. The vocabulary contains {len(p_index)} unique terms.\")\n",
    "    return p_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44174561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Indexing ---\n",
      "Finished indexing. The vocabulary contains 6539 unique terms.\n",
      "Term: 'experimental'\n",
      "  DocID: 0, Positions: [0, 5, 10]\n",
      "  DocID: 10, Positions: [55]\n",
      "  DocID: 11, Positions: [34]\n",
      "  DocID: 16, Positions: [36]\n",
      "  DocID: 18, Positions: [34]\n",
      "  DocID: 24, Positions: [92]\n",
      "  DocID: 28, Positions: [141]\n",
      "  DocID: 29, Positions: [29]\n",
      "  DocID: 34, Positions: [67]\n",
      "  DocID: 40, Positions: [34]\n",
      "  DocID: 41, Positions: [118]\n",
      "  DocID: 46, Positions: [121]\n",
      "  DocID: 51, Positions: [10, 22]\n",
      "  DocID: 52, Positions: [14]\n",
      "  DocID: 57, Positions: [69]\n",
      "  DocID: 68, Positions: [81]\n",
      "  DocID: 69, Positions: [21]\n",
      "  DocID: 73, Positions: [0, 8]\n",
      "  DocID: 77, Positions: [84]\n",
      "  DocID: 83, Positions: [0, 8, 19]\n",
      "  DocID: 98, Positions: [96, 133]\n",
      "  DocID: 100, Positions: [196]\n",
      "  DocID: 102, Positions: [63]\n",
      "  DocID: 111, Positions: [87]\n",
      "  DocID: 114, Positions: [98]\n",
      "  DocID: 120, Positions: [85]\n",
      "  DocID: 122, Positions: [25, 51]\n",
      "  DocID: 136, Positions: [11]\n",
      "  DocID: 139, Positions: [107]\n",
      "  DocID: 141, Positions: [21]\n",
      "  DocID: 153, Positions: [42]\n",
      "  DocID: 155, Positions: [12]\n",
      "  DocID: 167, Positions: [98]\n",
      "  DocID: 169, Positions: [138]\n",
      "  DocID: 170, Positions: [76]\n",
      "  DocID: 172, Positions: [20, 66]\n",
      "  DocID: 175, Positions: [17]\n",
      "  DocID: 178, Positions: [131, 143]\n",
      "  DocID: 182, Positions: [71]\n",
      "  DocID: 183, Positions: [57]\n",
      "  DocID: 185, Positions: [37, 58]\n",
      "  DocID: 186, Positions: [18]\n",
      "  DocID: 187, Positions: [124]\n",
      "  DocID: 188, Positions: [0, 10]\n",
      "  DocID: 190, Positions: [113]\n",
      "  DocID: 194, Positions: [31, 88, 103]\n",
      "  DocID: 196, Positions: [59, 134]\n",
      "  DocID: 201, Positions: [120]\n",
      "  DocID: 202, Positions: [43]\n",
      "  DocID: 205, Positions: [140, 146]\n",
      "  DocID: 206, Positions: [48, 94]\n",
      "  DocID: 211, Positions: [225]\n",
      "  DocID: 215, Positions: [129]\n",
      "  DocID: 219, Positions: [45]\n",
      "  DocID: 221, Positions: [78]\n",
      "  DocID: 224, Positions: [188]\n",
      "  DocID: 226, Positions: [86]\n",
      "  DocID: 229, Positions: [106]\n",
      "  DocID: 233, Positions: [102, 120, 150, 162]\n",
      "  DocID: 244, Positions: [17]\n",
      "  DocID: 250, Positions: [51]\n",
      "  DocID: 255, Positions: [0, 9, 18]\n",
      "  DocID: 256, Positions: [107]\n",
      "  DocID: 261, Positions: [109]\n",
      "  DocID: 270, Positions: [0, 7, 21]\n",
      "  DocID: 272, Positions: [45]\n",
      "  DocID: 276, Positions: [53]\n",
      "  DocID: 281, Positions: [156]\n",
      "  DocID: 282, Positions: [84]\n",
      "  DocID: 285, Positions: [25]\n",
      "  DocID: 293, Positions: [57]\n",
      "  DocID: 294, Positions: [16]\n",
      "  DocID: 303, Positions: [166]\n",
      "  DocID: 306, Positions: [84]\n",
      "  DocID: 328, Positions: [59, 368]\n",
      "  DocID: 329, Positions: [42]\n",
      "  DocID: 333, Positions: [129, 150]\n",
      "  DocID: 337, Positions: [31]\n",
      "  DocID: 338, Positions: [0, 11]\n",
      "  DocID: 343, Positions: [0, 5, 181]\n",
      "  DocID: 344, Positions: [30]\n",
      "  DocID: 345, Positions: [65, 117]\n",
      "  DocID: 346, Positions: [10]\n",
      "  DocID: 353, Positions: [71]\n",
      "  DocID: 359, Positions: [43]\n",
      "  DocID: 368, Positions: [54]\n",
      "  DocID: 369, Positions: [87]\n",
      "  DocID: 371, Positions: [0, 11, 22]\n",
      "  DocID: 376, Positions: [57]\n",
      "  DocID: 396, Positions: [38]\n",
      "  DocID: 408, Positions: [62]\n",
      "  DocID: 410, Positions: [17, 53]\n",
      "  DocID: 412, Positions: [83, 87]\n",
      "  DocID: 417, Positions: [13]\n",
      "  DocID: 419, Positions: [0, 10]\n",
      "  DocID: 420, Positions: [91]\n",
      "  DocID: 422, Positions: [0, 10]\n",
      "  DocID: 426, Positions: [87]\n",
      "  DocID: 434, Positions: [85]\n",
      "  DocID: 438, Positions: [105]\n",
      "  DocID: 440, Positions: [98]\n",
      "  DocID: 441, Positions: [26, 80]\n",
      "  DocID: 452, Positions: [22]\n",
      "  DocID: 454, Positions: [46, 49]\n",
      "  DocID: 461, Positions: [37]\n",
      "  DocID: 463, Positions: [16]\n",
      "  DocID: 466, Positions: [119]\n",
      "  DocID: 482, Positions: [24, 31, 142]\n",
      "  DocID: 492, Positions: [85, 97]\n",
      "  DocID: 494, Positions: [71]\n",
      "  DocID: 495, Positions: [1, 10]\n",
      "  DocID: 496, Positions: [78]\n",
      "  DocID: 499, Positions: [40]\n",
      "  DocID: 501, Positions: [28]\n",
      "  DocID: 502, Positions: [98]\n",
      "  DocID: 503, Positions: [18]\n",
      "  DocID: 509, Positions: [20]\n",
      "  DocID: 516, Positions: [90]\n",
      "  DocID: 518, Positions: [32, 97]\n",
      "  DocID: 520, Positions: [24, 45, 188]\n",
      "  DocID: 534, Positions: [132]\n",
      "  DocID: 538, Positions: [71]\n",
      "  DocID: 542, Positions: [1, 10, 59]\n",
      "  DocID: 547, Positions: [0, 10]\n",
      "  DocID: 550, Positions: [68, 101]\n",
      "  DocID: 551, Positions: [97]\n",
      "  DocID: 556, Positions: [0, 12]\n",
      "  DocID: 561, Positions: [76]\n",
      "  DocID: 565, Positions: [54]\n",
      "  DocID: 567, Positions: [0, 12]\n",
      "  DocID: 570, Positions: [45, 132, 230, 251]\n",
      "  DocID: 574, Positions: [212]\n",
      "  DocID: 586, Positions: [159]\n",
      "  DocID: 593, Positions: [19]\n",
      "  DocID: 598, Positions: [28]\n",
      "  DocID: 604, Positions: [39]\n",
      "  DocID: 608, Positions: [35]\n",
      "  DocID: 630, Positions: [48]\n",
      "  DocID: 632, Positions: [96]\n",
      "  DocID: 633, Positions: [28]\n",
      "  DocID: 634, Positions: [30]\n",
      "  DocID: 642, Positions: [68]\n",
      "  DocID: 643, Positions: [8]\n",
      "  DocID: 647, Positions: [44]\n",
      "  DocID: 660, Positions: [1, 18]\n",
      "  DocID: 661, Positions: [70, 80]\n",
      "  DocID: 664, Positions: [80, 83]\n",
      "  DocID: 668, Positions: [21]\n",
      "  DocID: 673, Positions: [83]\n",
      "  DocID: 676, Positions: [34]\n",
      "  DocID: 677, Positions: [93]\n",
      "  DocID: 683, Positions: [163, 194, 207]\n",
      "  DocID: 686, Positions: [18, 38, 78, 102]\n",
      "  DocID: 687, Positions: [57, 126]\n",
      "  DocID: 692, Positions: [39]\n",
      "  DocID: 702, Positions: [174, 193]\n",
      "  DocID: 710, Positions: [199]\n",
      "  DocID: 711, Positions: [40]\n",
      "  DocID: 715, Positions: [71]\n",
      "  DocID: 718, Positions: [36]\n",
      "  DocID: 726, Positions: [43]\n",
      "  DocID: 727, Positions: [82]\n",
      "  DocID: 737, Positions: [64]\n",
      "  DocID: 738, Positions: [30]\n",
      "  DocID: 741, Positions: [72]\n",
      "  DocID: 751, Positions: [23]\n",
      "  DocID: 758, Positions: [19, 55, 67]\n",
      "  DocID: 764, Positions: [0, 21, 92]\n",
      "  DocID: 765, Positions: [105, 139, 143]\n",
      "  DocID: 770, Positions: [0, 6, 14]\n",
      "  DocID: 779, Positions: [110, 122]\n",
      "  DocID: 788, Positions: [128]\n",
      "  DocID: 799, Positions: [0, 12, 26]\n",
      "  DocID: 800, Positions: [70]\n",
      "  DocID: 804, Positions: [138]\n",
      "  DocID: 814, Positions: [0, 17]\n",
      "  DocID: 818, Positions: [117]\n",
      "  DocID: 821, Positions: [51, 66]\n",
      "  DocID: 823, Positions: [22]\n",
      "  DocID: 825, Positions: [167]\n",
      "  DocID: 827, Positions: [61]\n",
      "  DocID: 828, Positions: [103]\n",
      "  DocID: 834, Positions: [1, 15, 60, 82, 86]\n",
      "  DocID: 842, Positions: [26]\n",
      "  DocID: 843, Positions: [86]\n",
      "  DocID: 844, Positions: [102]\n",
      "  DocID: 845, Positions: [0, 6]\n",
      "  DocID: 854, Positions: [0, 7, 14, 66]\n",
      "  DocID: 855, Positions: [0, 20, 40]\n",
      "  DocID: 856, Positions: [0, 20, 89]\n",
      "  DocID: 861, Positions: [46, 61]\n",
      "  DocID: 864, Positions: [11, 63]\n",
      "  DocID: 865, Positions: [47]\n",
      "  DocID: 867, Positions: [150]\n",
      "  DocID: 876, Positions: [0, 6]\n",
      "  DocID: 879, Positions: [44]\n",
      "  DocID: 885, Positions: [61]\n",
      "  DocID: 889, Positions: [28, 32]\n",
      "  DocID: 905, Positions: [127]\n",
      "  DocID: 909, Positions: [0, 9]\n",
      "  DocID: 910, Positions: [88]\n",
      "  DocID: 921, Positions: [70]\n",
      "  DocID: 922, Positions: [102]\n",
      "  DocID: 925, Positions: [66]\n",
      "  DocID: 926, Positions: [42, 164, 234]\n",
      "  DocID: 930, Positions: [12, 29]\n",
      "  DocID: 933, Positions: [44, 49]\n",
      "  DocID: 944, Positions: [89]\n",
      "  DocID: 948, Positions: [2, 13, 38, 67]\n",
      "  DocID: 949, Positions: [48]\n",
      "  DocID: 952, Positions: [13, 51]\n",
      "  DocID: 953, Positions: [16]\n",
      "  DocID: 957, Positions: [9]\n",
      "  DocID: 959, Positions: [72]\n",
      "  DocID: 962, Positions: [72]\n",
      "  DocID: 963, Positions: [47]\n",
      "  DocID: 972, Positions: [74]\n",
      "  DocID: 982, Positions: [48, 80]\n",
      "  DocID: 984, Positions: [7, 23, 58, 189]\n",
      "  DocID: 993, Positions: [26]\n",
      "  DocID: 994, Positions: [0, 6, 12, 93]\n",
      "  DocID: 996, Positions: [154]\n",
      "  DocID: 1003, Positions: [52]\n",
      "  DocID: 1005, Positions: [11]\n",
      "  DocID: 1013, Positions: [52]\n",
      "  DocID: 1016, Positions: [51, 94, 119]\n",
      "  DocID: 1025, Positions: [103]\n",
      "  DocID: 1036, Positions: [12, 73, 117]\n",
      "  DocID: 1037, Positions: [12]\n",
      "  DocID: 1042, Positions: [11]\n",
      "  DocID: 1043, Positions: [43]\n",
      "  DocID: 1046, Positions: [48]\n",
      "  DocID: 1048, Positions: [80]\n",
      "  DocID: 1059, Positions: [0, 11, 41]\n",
      "  DocID: 1063, Positions: [174, 226]\n",
      "  DocID: 1066, Positions: [14]\n",
      "  DocID: 1067, Positions: [61]\n",
      "  DocID: 1071, Positions: [1, 10, 63]\n",
      "  DocID: 1072, Positions: [0, 14]\n",
      "  DocID: 1073, Positions: [65]\n",
      "  DocID: 1075, Positions: [53]\n",
      "  DocID: 1077, Positions: [53]\n",
      "  DocID: 1078, Positions: [79]\n",
      "  DocID: 1079, Positions: [183]\n",
      "  DocID: 1080, Positions: [46]\n",
      "  DocID: 1089, Positions: [22]\n",
      "  DocID: 1094, Positions: [0, 3, 9]\n",
      "  DocID: 1095, Positions: [0, 8]\n",
      "  DocID: 1109, Positions: [85]\n",
      "  DocID: 1115, Positions: [29, 41]\n",
      "  DocID: 1119, Positions: [79, 82]\n",
      "  DocID: 1122, Positions: [78]\n",
      "  DocID: 1124, Positions: [101]\n",
      "  DocID: 1142, Positions: [66]\n",
      "  DocID: 1143, Positions: [8]\n",
      "  DocID: 1148, Positions: [27]\n",
      "  DocID: 1150, Positions: [23]\n",
      "  DocID: 1152, Positions: [0, 13]\n",
      "  DocID: 1153, Positions: [0, 12, 24]\n",
      "  DocID: 1155, Positions: [36]\n",
      "  DocID: 1156, Positions: [0, 17]\n",
      "  DocID: 1157, Positions: [35, 68]\n",
      "  DocID: 1158, Positions: [15, 48]\n",
      "  DocID: 1164, Positions: [0, 12]\n",
      "  DocID: 1168, Positions: [54]\n",
      "  DocID: 1174, Positions: [14]\n",
      "  DocID: 1182, Positions: [96]\n",
      "  DocID: 1183, Positions: [58]\n",
      "  DocID: 1184, Positions: [70]\n",
      "  DocID: 1189, Positions: [81]\n",
      "  DocID: 1192, Positions: [166]\n",
      "  DocID: 1193, Positions: [12, 25]\n",
      "  DocID: 1195, Positions: [123]\n",
      "  DocID: 1196, Positions: [122]\n",
      "  DocID: 1201, Positions: [0, 14, 146]\n",
      "  DocID: 1202, Positions: [20]\n",
      "  DocID: 1206, Positions: [11, 81, 151]\n",
      "  DocID: 1209, Positions: [20]\n",
      "  DocID: 1210, Positions: [78, 111]\n",
      "  DocID: 1211, Positions: [35, 41, 57]\n",
      "  DocID: 1213, Positions: [87]\n",
      "  DocID: 1215, Positions: [0, 12]\n",
      "  DocID: 1217, Positions: [13]\n",
      "  DocID: 1219, Positions: [122]\n",
      "  DocID: 1222, Positions: [88, 142, 157]\n",
      "  DocID: 1224, Positions: [16]\n",
      "  DocID: 1225, Positions: [77]\n",
      "  DocID: 1227, Positions: [14]\n",
      "  DocID: 1228, Positions: [49]\n",
      "  DocID: 1231, Positions: [61]\n",
      "  DocID: 1234, Positions: [71]\n",
      "  DocID: 1258, Positions: [149]\n",
      "  DocID: 1259, Positions: [73]\n",
      "  DocID: 1260, Positions: [91]\n",
      "  DocID: 1261, Positions: [14]\n",
      "  DocID: 1265, Positions: [87]\n",
      "  DocID: 1266, Positions: [34, 41]\n",
      "  DocID: 1274, Positions: [121]\n",
      "  DocID: 1287, Positions: [44]\n",
      "  DocID: 1295, Positions: [66]\n",
      "  DocID: 1299, Positions: [81, 90]\n",
      "  DocID: 1307, Positions: [155]\n",
      "  DocID: 1311, Positions: [24, 31]\n",
      "  DocID: 1334, Positions: [12, 90]\n",
      "  DocID: 1335, Positions: [24, 99]\n",
      "  DocID: 1336, Positions: [135]\n",
      "  DocID: 1338, Positions: [59]\n",
      "  DocID: 1349, Positions: [106, 123]\n",
      "  DocID: 1360, Positions: [64, 101]\n",
      "  DocID: 1361, Positions: [0, 7]\n",
      "  DocID: 1366, Positions: [42]\n",
      "  DocID: 1369, Positions: [19]\n",
      "  DocID: 1371, Positions: [72]\n",
      "  DocID: 1381, Positions: [92]\n",
      "  DocID: 1387, Positions: [97]\n",
      "  DocID: 1389, Positions: [142]\n",
      "  DocID: 1393, Positions: [69]\n",
      "  DocID: 1394, Positions: [50]\n",
      "Term: 'investigation'\n",
      "  DocID: 0, Positions: [1, 6]\n",
      "  DocID: 7, Positions: [73]\n",
      "  DocID: 8, Positions: [24, 194]\n",
      "  DocID: 18, Positions: [0, 7]\n",
      "  DocID: 28, Positions: [142]\n",
      "  DocID: 29, Positions: [2, 11]\n",
      "  DocID: 33, Positions: [78]\n",
      "  DocID: 43, Positions: [95]\n",
      "  DocID: 44, Positions: [0, 9]\n",
      "  DocID: 49, Positions: [0, 9, 19]\n",
      "  DocID: 55, Positions: [54]\n",
      "  DocID: 72, Positions: [0, 7]\n",
      "  DocID: 73, Positions: [29]\n",
      "  DocID: 77, Positions: [13]\n",
      "  DocID: 78, Positions: [14]\n",
      "  DocID: 79, Positions: [30]\n",
      "  DocID: 81, Positions: [1, 16, 119]\n",
      "  DocID: 83, Positions: [1, 9, 20]\n",
      "  DocID: 88, Positions: [0, 6, 15, 50]\n",
      "  DocID: 89, Positions: [14]\n",
      "  DocID: 98, Positions: [73, 90]\n",
      "  DocID: 101, Positions: [11]\n",
      "  DocID: 119, Positions: [54]\n",
      "  DocID: 125, Positions: [0, 6, 12, 32]\n",
      "  DocID: 127, Positions: [17]\n",
      "  DocID: 128, Positions: [0, 6]\n",
      "  DocID: 134, Positions: [36]\n",
      "  DocID: 138, Positions: [41]\n",
      "  DocID: 164, Positions: [159]\n",
      "  DocID: 169, Positions: [139]\n",
      "  DocID: 172, Positions: [21]\n",
      "  DocID: 173, Positions: [0, 16, 32]\n",
      "  DocID: 175, Positions: [18]\n",
      "  DocID: 178, Positions: [16, 99]\n",
      "  DocID: 183, Positions: [10]\n",
      "  DocID: 184, Positions: [29]\n",
      "  DocID: 186, Positions: [0, 9]\n",
      "  DocID: 187, Positions: [16, 89]\n",
      "  DocID: 188, Positions: [1, 11]\n",
      "  DocID: 196, Positions: [29]\n",
      "  DocID: 197, Positions: [0, 9, 18, 45]\n",
      "  DocID: 201, Positions: [52, 91]\n",
      "  DocID: 204, Positions: [26]\n",
      "  DocID: 206, Positions: [15]\n",
      "  DocID: 211, Positions: [38]\n",
      "  DocID: 212, Positions: [8]\n",
      "  DocID: 213, Positions: [15]\n",
      "  DocID: 215, Positions: [8, 43]\n",
      "  DocID: 221, Positions: [18, 76, 79]\n",
      "  DocID: 224, Positions: [94]\n",
      "  DocID: 227, Positions: [17]\n",
      "  DocID: 242, Positions: [0, 7, 24]\n",
      "  DocID: 244, Positions: [18]\n",
      "  DocID: 245, Positions: [22]\n",
      "  DocID: 250, Positions: [52]\n",
      "  DocID: 251, Positions: [0, 12]\n",
      "  DocID: 259, Positions: [30]\n",
      "  DocID: 264, Positions: [44]\n",
      "  DocID: 271, Positions: [44]\n",
      "  DocID: 279, Positions: [39]\n",
      "  DocID: 292, Positions: [30]\n",
      "  DocID: 293, Positions: [0, 11]\n",
      "  DocID: 311, Positions: [30]\n",
      "  DocID: 313, Positions: [99]\n",
      "  DocID: 338, Positions: [35]\n",
      "  DocID: 341, Positions: [102]\n",
      "  DocID: 343, Positions: [16]\n",
      "  DocID: 364, Positions: [33]\n",
      "  DocID: 369, Positions: [88]\n",
      "  DocID: 371, Positions: [1, 12, 23, 69]\n",
      "  DocID: 373, Positions: [0, 5]\n",
      "  DocID: 389, Positions: [25]\n",
      "  DocID: 422, Positions: [1, 11]\n",
      "  DocID: 426, Positions: [41, 88]\n",
      "  DocID: 432, Positions: [33]\n",
      "  DocID: 433, Positions: [24, 83]\n",
      "  DocID: 435, Positions: [16]\n",
      "  DocID: 441, Positions: [27, 81, 84]\n",
      "  DocID: 461, Positions: [38, 75]\n",
      "  DocID: 462, Positions: [5, 11, 26]\n",
      "  DocID: 468, Positions: [63]\n",
      "  DocID: 472, Positions: [9]\n",
      "  DocID: 488, Positions: [25]\n",
      "  DocID: 495, Positions: [2, 11, 33]\n",
      "  DocID: 503, Positions: [19]\n",
      "  DocID: 511, Positions: [47]\n",
      "  DocID: 520, Positions: [25, 53]\n",
      "  DocID: 525, Positions: [37]\n",
      "  DocID: 538, Positions: [72]\n",
      "  DocID: 547, Positions: [37, 51]\n",
      "  DocID: 550, Positions: [102]\n",
      "  DocID: 551, Positions: [98]\n",
      "  DocID: 552, Positions: [15]\n",
      "  DocID: 564, Positions: [0, 12]\n",
      "  DocID: 565, Positions: [87, 94]\n",
      "  DocID: 567, Positions: [1, 13]\n",
      "  DocID: 569, Positions: [24]\n",
      "  DocID: 621, Positions: [50]\n",
      "  DocID: 623, Positions: [47, 59, 89, 128]\n",
      "  DocID: 632, Positions: [34]\n",
      "  DocID: 633, Positions: [29]\n",
      "  DocID: 634, Positions: [31, 138]\n",
      "  DocID: 636, Positions: [26]\n",
      "  DocID: 641, Positions: [0, 9]\n",
      "  DocID: 649, Positions: [48]\n",
      "  DocID: 653, Positions: [34]\n",
      "  DocID: 656, Positions: [125]\n",
      "  DocID: 660, Positions: [2, 19, 64]\n",
      "  DocID: 663, Positions: [30]\n",
      "  DocID: 671, Positions: [0, 12, 24, 44, 87]\n",
      "  DocID: 677, Positions: [94]\n",
      "  DocID: 687, Positions: [0, 17]\n",
      "  DocID: 690, Positions: [0, 16, 32, 75]\n",
      "  DocID: 691, Positions: [0, 16, 32, 82]\n",
      "  DocID: 692, Positions: [40]\n",
      "  DocID: 693, Positions: [36, 183]\n",
      "  DocID: 694, Positions: [40, 149]\n",
      "  DocID: 697, Positions: [111]\n",
      "  DocID: 698, Positions: [42]\n",
      "  DocID: 707, Positions: [34]\n",
      "  DocID: 708, Positions: [16, 124]\n",
      "  DocID: 709, Positions: [0, 17, 34]\n",
      "  DocID: 710, Positions: [30, 103, 195, 205]\n",
      "  DocID: 711, Positions: [41, 66, 84]\n",
      "  DocID: 728, Positions: [90]\n",
      "  DocID: 737, Positions: [67]\n",
      "  DocID: 739, Positions: [15]\n",
      "  DocID: 741, Positions: [45]\n",
      "  DocID: 745, Positions: [23, 40]\n",
      "  DocID: 755, Positions: [0, 18]\n",
      "  DocID: 757, Positions: [1, 16]\n",
      "  DocID: 764, Positions: [1, 22]\n",
      "  DocID: 770, Positions: [15]\n",
      "  DocID: 778, Positions: [28, 51]\n",
      "  DocID: 780, Positions: [67, 104, 126, 140]\n",
      "  DocID: 794, Positions: [0, 20]\n",
      "  DocID: 795, Positions: [23]\n",
      "  DocID: 797, Positions: [121]\n",
      "  DocID: 799, Positions: [27, 90]\n",
      "  DocID: 802, Positions: [2, 7]\n",
      "  DocID: 806, Positions: [0, 15, 30]\n",
      "  DocID: 807, Positions: [0, 20, 40]\n",
      "  DocID: 809, Positions: [0, 6, 15]\n",
      "  DocID: 810, Positions: [0, 14]\n",
      "  DocID: 813, Positions: [0, 19]\n",
      "  DocID: 814, Positions: [1, 18]\n",
      "  DocID: 816, Positions: [60]\n",
      "  DocID: 823, Positions: [63]\n",
      "  DocID: 824, Positions: [98]\n",
      "  DocID: 826, Positions: [91]\n",
      "  DocID: 834, Positions: [2, 16]\n",
      "  DocID: 839, Positions: [27]\n",
      "  DocID: 842, Positions: [27]\n",
      "  DocID: 843, Positions: [87]\n",
      "  DocID: 853, Positions: [38]\n",
      "  DocID: 856, Positions: [1, 21]\n",
      "  DocID: 857, Positions: [30]\n",
      "  DocID: 873, Positions: [2, 5]\n",
      "  DocID: 876, Positions: [5, 11]\n",
      "  DocID: 885, Positions: [62]\n",
      "  DocID: 890, Positions: [19]\n",
      "  DocID: 900, Positions: [2, 11]\n",
      "  DocID: 903, Positions: [57]\n",
      "  DocID: 905, Positions: [46, 86]\n",
      "  DocID: 925, Positions: [0, 11]\n",
      "  DocID: 930, Positions: [13]\n",
      "  DocID: 931, Positions: [83]\n",
      "  DocID: 944, Positions: [1, 16]\n",
      "  DocID: 950, Positions: [41]\n",
      "  DocID: 951, Positions: [26]\n",
      "  DocID: 957, Positions: [12]\n",
      "  DocID: 958, Positions: [0, 4]\n",
      "  DocID: 968, Positions: [52]\n",
      "  DocID: 969, Positions: [28]\n",
      "  DocID: 970, Positions: [32]\n",
      "  DocID: 984, Positions: [59]\n",
      "  DocID: 990, Positions: [20, 160]\n",
      "  DocID: 991, Positions: [40]\n",
      "  DocID: 992, Positions: [0, 9]\n",
      "  DocID: 993, Positions: [27]\n",
      "  DocID: 994, Positions: [33]\n",
      "  DocID: 998, Positions: [2, 14]\n",
      "  DocID: 999, Positions: [1, 7]\n",
      "  DocID: 1016, Positions: [95]\n",
      "  DocID: 1036, Positions: [13]\n",
      "  DocID: 1053, Positions: [33]\n",
      "  DocID: 1059, Positions: [2, 13]\n",
      "  DocID: 1060, Positions: [51]\n",
      "  DocID: 1062, Positions: [2, 12]\n",
      "  DocID: 1063, Positions: [135]\n",
      "  DocID: 1065, Positions: [75]\n",
      "  DocID: 1069, Positions: [11]\n",
      "  DocID: 1071, Positions: [2, 11]\n",
      "  DocID: 1072, Positions: [2, 16]\n",
      "  DocID: 1075, Positions: [50]\n",
      "  DocID: 1079, Positions: [184]\n",
      "  DocID: 1080, Positions: [0, 5]\n",
      "  DocID: 1088, Positions: [3, 16]\n",
      "  DocID: 1089, Positions: [23]\n",
      "  DocID: 1090, Positions: [19]\n",
      "  DocID: 1091, Positions: [0, 18, 36]\n",
      "  DocID: 1092, Positions: [0, 15, 30]\n",
      "  DocID: 1094, Positions: [10]\n",
      "  DocID: 1095, Positions: [1, 9]\n",
      "  DocID: 1097, Positions: [1, 4]\n",
      "  DocID: 1101, Positions: [19]\n",
      "  DocID: 1111, Positions: [44]\n",
      "  DocID: 1113, Positions: [33]\n",
      "  DocID: 1116, Positions: [71]\n",
      "  DocID: 1127, Positions: [74]\n",
      "  DocID: 1141, Positions: [28, 166]\n",
      "  DocID: 1142, Positions: [67]\n",
      "  DocID: 1143, Positions: [9]\n",
      "  DocID: 1152, Positions: [1, 14]\n",
      "  DocID: 1153, Positions: [1, 13, 25]\n",
      "  DocID: 1156, Positions: [1, 18]\n",
      "  DocID: 1158, Positions: [16]\n",
      "  DocID: 1159, Positions: [2, 18, 34, 69]\n",
      "  DocID: 1160, Positions: [2, 16, 30, 64]\n",
      "  DocID: 1161, Positions: [32, 93]\n",
      "  DocID: 1162, Positions: [0, 8]\n",
      "  DocID: 1163, Positions: [0, 12, 25]\n",
      "  DocID: 1174, Positions: [15]\n",
      "  DocID: 1196, Positions: [1, 10]\n",
      "  DocID: 1202, Positions: [21]\n",
      "  DocID: 1210, Positions: [30]\n",
      "  DocID: 1217, Positions: [14]\n",
      "  DocID: 1222, Positions: [84, 89]\n",
      "  DocID: 1224, Positions: [17]\n",
      "  DocID: 1227, Positions: [15]\n",
      "  DocID: 1228, Positions: [50]\n",
      "  DocID: 1236, Positions: [6]\n",
      "  DocID: 1244, Positions: [65]\n",
      "  DocID: 1268, Positions: [77]\n",
      "  DocID: 1269, Positions: [16]\n",
      "  DocID: 1271, Positions: [48, 57]\n",
      "  DocID: 1306, Positions: [97]\n",
      "  DocID: 1310, Positions: [351, 357, 371]\n",
      "  DocID: 1314, Positions: [9]\n",
      "  DocID: 1316, Positions: [47, 60]\n",
      "  DocID: 1317, Positions: [21]\n",
      "  DocID: 1320, Positions: [0, 10]\n",
      "  DocID: 1334, Positions: [14]\n",
      "  DocID: 1335, Positions: [0, 12, 25]\n",
      "  DocID: 1338, Positions: [0, 11, 22]\n",
      "  DocID: 1340, Positions: [57]\n",
      "  DocID: 1346, Positions: [30]\n",
      "  DocID: 1349, Positions: [1, 16, 31]\n",
      "  DocID: 1350, Positions: [0, 6]\n",
      "  DocID: 1351, Positions: [0, 11]\n",
      "  DocID: 1361, Positions: [1, 8, 16, 79]\n",
      "  DocID: 1364, Positions: [1, 16]\n",
      "  DocID: 1370, Positions: [70]\n",
      "  DocID: 1374, Positions: [1, 10]\n",
      "  DocID: 1378, Positions: [161]\n",
      "  DocID: 1380, Positions: [22]\n",
      "  DocID: 1384, Positions: [25]\n",
      "  DocID: 1392, Positions: [59]\n",
      "  DocID: 1397, Positions: [24]\n"
     ]
    }
   ],
   "source": [
    "p_index = make_positional_index(processed_articles)\n",
    "\n",
    "# --- Display a sample of the positional index ---\n",
    "\n",
    "for i, (term, postings) in enumerate(p_index.items()):\n",
    "    if i >= 2:  # Limit to first 2 terms for brevity\n",
    "        break\n",
    "    print(f\"Term: '{term}'\")\n",
    "    for docid, positions in postings.items():\n",
    "        print(f\"  DocID: {docid}, Positions: {positions}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
